<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Wush Wu and Michael Benesty" />


<title>FeatureHashing</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<style type="text/css">body {
margin: 0 auto;
background-color: white;

/ font-family:Georgia, Palatino, serif;
font-family: "Open Sans", "Book Antiqua", Palatino, serif;
/ font-family:Arial, Helvetica, sans-serif;
/ font-family:Tahoma, Verdana, Geneva, sans-serif;
/ font-family:Courier, monospace;
/ font-family:"Times New Roman", Times, serif;
	color: #333333; 
/ color: #000000; 
/ color: #666666; 	/ color: #E3E3E3; 
/ color: white; line-height: 100%;
max-width: 800px;
padding: 10px;
font-size: 17px;
text-align: justify;
text-justify: inter-word;
}
p {
line-height: 150%;
/ max-width: 540px;
max-width: 960px;
margin-bottom: 5px;
font-weight: 400; / color: #333333
}
h1, h2, h3, h4, h5, h6 {
font-weight: 400;
margin-top: 35px;
margin-bottom: 15px;
padding-top: 10px;
}
h1 {
margin-top: 70px;
color: #606AAA;
font-size:230%;
font-variant:small-caps;
padding-bottom:20px;
width:100%;
border-bottom:1px solid #606AAA;
}
h2 {
font-size:160%;
}
h3 {
font-size:130%;
}
h4 {
font-size:120%;
font-variant:small-caps;
}
h5 {
font-size:120%;
}
h6 {
font-size:120%;
font-variant:small-caps;
}
a {
color: #606AAA;
margin: 0;
padding: 0;
vertical-align: baseline;
}
a:hover {
text-decoration: blink;
color: green;
}
a:visited {
color: gray;
}
ul, ol {
padding: 0;
margin: 0px 0px 0px 50px;
}
ul {
list-style-type: square;
list-style-position: inside;
}
li {
line-height:150% }
li ul, li ul {
margin-left: 24px;
}
pre {
padding: 0px 10px;
max-width: 800px;
white-space: pre-wrap;
}
code {
font-family: Consolas, Monaco, Andale Mono, monospace, courrier new;
line-height: 1.5;
font-size: 15px;
background: #F8F8F8;
border-radius: 4px;
padding: 5px;
display: inline-block;
max-width: 800px;
white-space: pre-wrap;
}
li code, p code {
background: #CDCDCD;
color: #606AAA;
padding: 0px 5px 0px 5px;
}
code.r, code.cpp {
display: block;
word-wrap: break-word;
border: 1px solid #606AAA; }
aside {
display: block;
float: right;
width: 390px;
}
blockquote {
border-left:.5em solid #606AAA;
background: #F8F8F8;
padding: 0em 1em 0em 1em;
margin-left:10px;
max-width: 500px;
}
blockquote cite {
line-height:10px;
color:#bfbfbf;
}
blockquote cite:before {
/content: '\2014 \00A0';
}
blockquote p, blockquote li { color: #666;
}
hr {
/ width: 540px;
text-align: left;
margin: 0 auto 0 0;
color: #999;
}

table {
width: 100%;
border-top: 1px solid #919699;
border-left: 1px solid #919699;
border-spacing: 0;
}
table th {
padding: 4px 8px 4px 8px;
text-align: center;
color: white;
background: #606AAA;
border-bottom: 1px solid #919699;
border-right: 1px solid #919699;
}
table th p {
font-weight: bold;
margin-bottom: 0px; }
table td {
padding: 8px;	vertical-align: top;
border-bottom: 1px solid #919699;
border-right: 1px solid #919699;
}
table td:last-child {
/background: lightgray;
text-align: right;
}
table td p {
margin-bottom: 0px; }
table td p + p {
margin-top: 5px; }
table td p + p + p {
margin-top: 5px; }</style>




</head>

<body>




<h1 class="title toc-ignore">FeatureHashing</h1>
<h4 class="author">Wush Wu and Michael Benesty</h4>


<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span>
Introduction</a></li>
<li><a href="#installation"><span class="toc-section-number">2</span>
Installation</a>
<ul>
<li><a href="#when-should-we-use-feature-hashing"><span class="toc-section-number">2.1</span> When should we use Feature
Hashing?</a></li>
</ul></li>
<li><a href="#getting-started"><span class="toc-section-number">3</span>
Getting Started</a>
<ul>
<li><a href="#logistic-regression-with-glmnet"><span class="toc-section-number">3.1</span> Logistic Regression with
<span><code>glmnet</code></span></a></li>
<li><a href="#gradient-boosted-decision-tree-with-xgboost"><span class="toc-section-number">3.2</span> Gradient Boosted Decision Tree
with <span><code>xgboost</code></span></a></li>
<li><a href="#per-coordinate-ftrl-proximal-with-l_1-and-l_2-regularization-for-logistic-regression"><span class="toc-section-number">3.3</span> Per-Coordinate FTRL-Proximal with
<span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> Regularization for Logistic
Regression</a></li>
</ul></li>
<li><a href="#supported-data-structure"><span class="toc-section-number">4</span> Supported Data Structure</a></li>
<li><a href="#reference">Reference</a></li>
</ul>
</div>

<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p><a href="https://en.wikipedia.org/wiki/Feature_hashing">Feature
hashing</a>, also called as the hashing trick, is a method to transform
features to vector. Without looking the indices up in an associative
array, it applies a hash function to the features and uses their hash
values as indices directly.</p>
<p>The package <strong>FeatureHashing</strong> implements the method in
<span class="citation">Weinberger et al. (2009)</span> to transform a
<code>data.frame</code> to sparse matrix. The package provides a formula
interface similar to <code>model.matrix</code> in <code>R</code> and
<code>Matrix::sparse.model.matrix</code> in the package
<code>Matrix</code>. Splitting of concatenated data, check the help of
<code>test.tag</code> for explanation of concatenated data, during the
construction of the model matrix.</p>
</div>
<div id="installation" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Installation</h1>
<p>To install the stable version from Cran, run this command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;FeatureHashing&quot;</span>)</span></code></pre></div>
<p>For up-to-date version, please install from github. Windows user will
need to install <a href="https://cran.r-project.org/bin/windows/Rtools/">RTools</a>
first.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&#39;wush978/FeatureHashing&#39;</span>)</span></code></pre></div>
<div id="when-should-we-use-feature-hashing" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> When should we use
Feature Hashing?</h2>
<p>Feature hashing is useful when the user does not easy to know the
dimension of the feature vector. For example, the bag-of-word
representation in document classification problem requires scanning
entire dataset to know how many words we have, i.e. the dimension of the
feature vector.</p>
<p>In general, feature hashing is useful in the following
environment:</p>
<ul>
<li>Streaming Environment</li>
<li>Distirbuted Environment</li>
</ul>
<p>Because it is expensive or impossible to know the real dimension of
the feature vector.</p>
</div>
</div>
<div id="getting-started" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Getting Started</h1>
<p>The following scripts show how to use the
<strong>FeatureHashing</strong> to construct
<code>Matrix::dgCMatrix</code> and train a model in other packages which
supports <code>Matrix::dgCMatrix</code> as input.</p>
<p>The dataset is a sample from iPinYou dataset which is described in
<span class="citation">Zhang et al. (2014)</span>.</p>
<div id="logistic-regression-with-glmnet" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Logistic Regression
with <a href="https://cran.r-project.org/package=glmnet"><code>glmnet</code></a></h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The following script assumes that the data.frame</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># of the training dataset and testing dataset are </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># assigned to variable `ipinyou.train` and `ipinyou.test`</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># respectively</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(FeatureHashing)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Checking version.</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fu">stopifnot</span>(<span class="fu">packageVersion</span>(<span class="st">&quot;FeatureHashing&quot;</span>) <span class="sc">&gt;=</span> <span class="fu">package_version</span>(<span class="st">&quot;0.9&quot;</span>))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(ipinyou)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="er">~</span> IP <span class="sc">+</span> Region <span class="sc">+</span> City <span class="sc">+</span> AdExchange <span class="sc">+</span> Domain <span class="sc">+</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  URL <span class="sc">+</span> AdSlotId <span class="sc">+</span> AdSlotWidth <span class="sc">+</span> AdSlotHeight <span class="sc">+</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>  AdSlotVisibility <span class="sc">+</span> AdSlotFormat <span class="sc">+</span> CreativeID <span class="sc">+</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  Adid <span class="sc">+</span> <span class="fu">split</span>(UserTag, <span class="at">delim =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># if the version of FeatureHashing is 0.8, please use the following command:</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># m.train &lt;- as(hashed.model.matrix(f, ipinyou.train, 2^16, transpose = FALSE), &quot;dgCMatrix&quot;)</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>m.train <span class="ot">&lt;-</span> <span class="fu">hashed.model.matrix</span>(f, ipinyou.train, <span class="dv">2</span><span class="sc">^</span><span class="dv">16</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>m.test <span class="ot">&lt;-</span> <span class="fu">hashed.model.matrix</span>(f, ipinyou.test, <span class="dv">2</span><span class="sc">^</span><span class="dv">16</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># logistic regression with glmnet</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span></code></pre></div>
<pre><code>## 載入需要的套件：Matrix</code></pre>
<pre><code>## Loaded glmnet 4.0-2</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>cv.g.lr <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(m.train, ipinyou.train<span class="sc">$</span>IsClick,</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)<span class="co">#, type.measure = &quot;auc&quot;)</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>p.lr <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv.g.lr, m.test, <span class="at">s=</span><span class="st">&quot;lambda.min&quot;</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pROC)</span></code></pre></div>
<pre><code>## Type &#39;citation(&quot;pROC&quot;)&#39; for a citation.</code></pre>
<pre><code>## 
## 載入套件：&#39;pROC&#39;</code></pre>
<pre><code>## 下列物件被遮斷自 &#39;package:stats&#39;:
## 
##     cov, smooth, var</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">auc</span>(ipinyou.test<span class="sc">$</span>IsClick, <span class="fu">c</span>(p.lr))</span></code></pre></div>
<pre><code>## Setting levels: control = FALSE, case = TRUE</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre><code>## Area under the curve: 0.5187</code></pre>
</div>
<div id="gradient-boosted-decision-tree-with-xgboost" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Gradient Boosted
Decision Tree with <a href="https://cran.r-project.org/package=xgboost"><code>xgboost</code></a></h2>
<p>Following the script above,</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># GBDT with xgboost</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="fu">require</span>(<span class="st">&quot;xgboost&quot;</span>)){</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  cv.g.gdbt <span class="ot">&lt;-</span> <span class="fu">xgboost</span>(m.train, ipinyou.train<span class="sc">$</span>IsClick, <span class="at">max.depth=</span><span class="dv">7</span>, <span class="at">eta=</span><span class="fl">0.1</span>, <span class="at">subsample =</span> <span class="fl">0.7</span>, <span class="at">colsample_bytree =</span> <span class="fl">0.7</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">nround =</span> <span class="dv">10</span>, <span class="at">objective =</span> <span class="st">&quot;binary:logistic&quot;</span>, <span class="at">verbose =</span> <span class="fu">ifelse</span>(<span class="fu">interactive</span>(), <span class="dv">1</span>, <span class="dv">0</span>))</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>  p.lm <span class="ot">&lt;-</span> <span class="fu">predict</span>(cv.g.gdbt, m.test)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">auc</span>(ipinyou.test<span class="sc">$</span>IsClick, p.lm)  </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## 載入需要的套件：xgboost</code></pre>
<pre><code>## [15:52:01] WARNING: amalgamation/../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective &#39;binary:logistic&#39; was changed from &#39;error&#39; to &#39;logloss&#39;. Explicitly set eval_metric if you&#39;d like to restore the old behavior.</code></pre>
<pre><code>## Setting levels: control = FALSE, case = TRUE</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre><code>## Area under the curve: 0.6292</code></pre>
</div>
<div id="per-coordinate-ftrl-proximal-with-l_1-and-l_2-regularization-for-logistic-regression" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Per-Coordinate
FTRL-Proximal with <span class="math inline">\(L_1\)</span> and <span class="math inline">\(L_2\)</span> Regularization for Logistic
Regression</h2>
<p>The following scripts use an implementation of the FTRL-Proximal for
Logistic Regresion, which is published in <span class="citation">McMahan
et al. (2013)</span>, to predict the probability (1-step prediction) and
update the model simultaneously.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="fu">system.file</span>(<span class="st">&quot;ftprl.R&quot;</span>, <span class="at">package =</span> <span class="st">&quot;FeatureHashing&quot;</span>))</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>m.train <span class="ot">&lt;-</span> <span class="fu">hashed.model.matrix</span>(f, ipinyou.train, <span class="dv">2</span><span class="sc">^</span><span class="dv">16</span>, <span class="at">transpose =</span> <span class="cn">TRUE</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>ftprl <span class="ot">&lt;-</span> <span class="fu">initialize.ftprl</span>(<span class="fl">0.1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="dv">2</span><span class="sc">^</span><span class="dv">16</span>)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>ftprl <span class="ot">&lt;-</span> <span class="fu">update.ftprl</span>(ftprl, m.train, ipinyou.train<span class="sc">$</span>IsClick, <span class="at">predict =</span> <span class="cn">TRUE</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="fu">auc</span>(ipinyou.train<span class="sc">$</span>IsClick, <span class="fu">attr</span>(ftprl, <span class="st">&quot;predict&quot;</span>))</span></code></pre></div>
<pre><code>## Setting levels: control = FALSE, case = TRUE</code></pre>
<pre><code>## Setting direction: controls &lt; cases</code></pre>
<pre><code>## Area under the curve: 0.5993</code></pre>
<p>If we use the same algorithm to predict the click through rate of the
3rd season of iPinYou, the overall AUC will be 0.77 which is comparable
to the overall AUC of the 3rd season 0.76 reported in <span class="citation">Zhang et al. (2014)</span>.</p>
</div>
</div>
<div id="supported-data-structure" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Supported Data
Structure</h1>
<ul>
<li>character and factor</li>
<li>numeric and integer</li>
<li>array, i.e. concatenated strings such as
<code>c(&quot;a,b&quot;, &quot;a,b,c&quot;, &quot;a,c&quot;, &quot;&quot;)</code></li>
</ul>
</div>
<div id="reference" class="section level1 unnumbered">
<h1 class="unnumbered">Reference</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DBLP:conf/kdd/McMahanHSYEGNPDGCLWHBK13" class="csl-entry">
McMahan, H. Brendan, Gary Holt, David Sculley, Michael Young, Dietmar
Ebner, Julian Grady, Lan Nie, et al. 2013. <span>“Ad Click Prediction: A
View from the Trenches.”</span> In <em>The 19th <span>ACM</span>
<span>SIGKDD</span> International Conference on Knowledge Discovery and
Data Mining, <span>KDD</span> 2013, Chicago, IL, USA, August 11-14,
2013</em>, edited by Inderjit S. Dhillon, Yehuda Koren, Rayid Ghani, Ted
E. Senator, Paul Bradley, Rajesh Parekh, Jingrui He, Robert L. Grossman,
and Ramasamy Uthurusamy, 1222–30. <span>ACM</span>. <a href="https://doi.org/10.1145/2487575.2488200">https://doi.org/10.1145/2487575.2488200</a>.
</div>
<div id="ref-DBLP:conf/icml/WeinbergerDLSA09" class="csl-entry">
Weinberger, Kilian Q., Anirban Dasgupta, John Langford, Alexander J.
Smola, and Josh Attenberg. 2009. <span>“Feature Hashing for Large Scale
Multitask Learning.”</span> In <em>Proceedings of the 26th Annual
International Conference on Machine Learning, <span>ICML</span> 2009,
Montreal, Quebec, Canada, June 14-18, 2009</em>, edited by Andrea
Pohoreckyj Danyluk, Léon Bottou, and Michael L. Littman, 1113–20. <a href="https://doi.org/10.1145/1553374.1553516">https://doi.org/10.1145/1553374.1553516</a>.
</div>
<div id="ref-zhang2014real" class="csl-entry">
Zhang, Weinan, Shuai Yuan, Jun Wang, and Xuehua Shen. 2014.
<span>“Real-Time Bidding Benchmarking with iPinYou Dataset.”</span>
<em>arXiv Preprint arXiv:1407.7073</em>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
